# Amazon Machine Learning without the console

This project is meant to demonstrate the functionality of the Amazon web service SDK for python (Boto). In particular it will show how to use Amazonâ€™s machine learning service and the s3 storage service without logging into the amazon console and using the interface. 


## Setting up

### Installation Requirements

This code requires Python 2.7 and has compatibility issues with python 3.5

Also make sure that Amazons python SDK boto3 is installed. It can be installed with the following pip command.              

`pip install boto3`


### Configuring credentials

By default, the SDK will look for a credentials file at `~/.aws/credentials` or
`C:\Users\USER_NAME\.aws\credentials` for Windows users.
The file should look like this (without spaces at the beginning of each line):

    [default]
    aws_access_key_id = YOUR_ACCESS_KEY_ID
    aws_secret_access_key = YOUR_SECRET_ACCESS_KEY
    
When producing batch-predictions results will be output to a s3 bucket. Make sure that the s3 bucket policy allows machine learning predictions to output there. The simplist way to set up the correct s3 bucket policy is to first run through a batch prediction using the amazon Machine learning console.   


## Sample code

There are two main scripts that follow the "banking" example in the
main documentation, but using the API instead of the web console.

The first script creates data sources, an ML model, and an evaluation
object.  This does everything needed to begin getting ready to make
predictions, and outputs the identifiers for all of the objects created.
It can be run as follows:

    python build_model.py "Trying the sample code"

The second script sets the score threshold, and kicks off a batch
prediction job, which uses the ML Model to generate predictions on
new data.  This script needs the id of the ML Model generated by
the first script, which will be output at the end of the script's
run.  But the command will be invoked like:

    python use_model.py ml-12345678901 0.77 s3://your-bucket/ml-output/

Of course, substituting "your-bucket" with the name of your own s3 bucket,
which has been configured to allow AML write access, and whatever S3 prefix
you like.

Note, the threshold 0.77 isn't special.  We're just using it as
an example.  You can figure out a good threshold for your application
by using the AWS console and viewing the ML Model's evaluation to
"Explore Performance".
